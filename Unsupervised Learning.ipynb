{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb1b15-39cd-4317-9e62-c42a70a2ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost==1.7.5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8596f-0d02-4b06-bc73-9d6089a410fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv',index_col=0)\n",
    "test_data = pd.read_csv('test_data.csv',index_col=0)\n",
    "train_data.index = range(len(train_data))\n",
    "train_data.loc[train_data['OCCUPATION']!=1,'OCCUPATION'] = 0\n",
    "test_data.index = range(len(test_data))\n",
    "test_data.loc[test_data['OCCUPATION']!=1,'OCCUPATION'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de62c3f-ccac-4870-988d-e1fb5d22a6f7",
   "metadata": {},
   "source": [
    "## Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fab4f2-cf02-4076-8f09-c485d11b2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we list all the categorical variables to be one hot encoded\n",
    "cat_vars = ['MARRIAGE', 'EDUCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33972e22-d62d-4571-a446-22299a2974bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder for each cat_vars\n",
    "encoders = [OneHotEncoder(categories='auto') for _ in range(len(cat_vars))] \n",
    "# encode each of the cat_vars with their respective encoder\n",
    "encoded_tr = [encoders[i].fit_transform(train_data[[cat_var]]).todense() for i,cat_var in enumerate(cat_vars)]\n",
    "encoded_test = [encoders[i].fit_transform(test_data[[cat_var]]).todense() for i,cat_var in enumerate(cat_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eeb03c-75e9-45ae-83a1-c1dff375d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the label column and also drop the cat_vars \n",
    "# this way we can combine the encoded categorical variables with the continuous variables \n",
    "X_train = pd.concat([train_data.iloc[:,:-1].drop(cat_vars, axis=1), \n",
    "                     pd.DataFrame(np.concatenate(encoded_tr, axis=1))], axis=1)\n",
    "X_test = pd.concat([test_data.iloc[:,:-1].drop(cat_vars, axis=1), \n",
    "                    pd.DataFrame(np.concatenate(encoded_test, axis=1))], axis=1)\n",
    "y_train = train_data.iloc[:,-1] \n",
    "y_test = test_data.iloc[:,-1]\n",
    "X_train = X_train.rename(columns={0:'Marriage 1',1:'Marriage 2',2:'Marriage 3',3:'Edu 1',4:'Edu 2',5:'Edu 3',\n",
    "                                  6:'Edu 4',7:'Edu 5',8:'Edu 6',9:'Edu 7'})\n",
    "# Note that in the testing data, we do not have Marriage 3 and Edu 6\n",
    "X_test = X_test.rename(columns={0:'Marriage 1',1:'Marriage 2',2:'Edu 1',3:'Edu 2',4:'Edu 3',\n",
    "                                  5:'Edu 4',6:'Edu 5',7:'Edu 7'})\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be3823-1d5e-4d08-ae80-7d07ad0e4417",
   "metadata": {},
   "source": [
    "### Normalize Continuous Features - For the testing data, the mean and standard deviation has been used from the training data to do the normalization.Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09e0e3-0667-4cd2-b0f0-67ec4b6e1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2,3,4,5,8]:\n",
    "    X1 = X_train.iloc[:,i]\n",
    "    mean = X1.mean()\n",
    "    std = X1.std()\n",
    "    X_train.iloc[:,i] = (X1-mean)/std\n",
    "    X_test.iloc[:,i] = (X_test.iloc[:,i]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5894a-e4a5-4e6d-a9ea-1bb4724aa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbae0c-9688-4281-b142-f641fa0f8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ce378-f9c5-4184-825a-c0211d0c8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of some dummy variables to avoid perfect multicollinearity\n",
    "X_train = X_train.drop(['Marriage 3','Edu 6'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90556f-f586-4d85-a8d1-7710e04a1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419145e7-4d71-4dde-a16b-b4927a2b48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38433d-e636-49cc-90a9-e4c68461973c",
   "metadata": {},
   "source": [
    "### Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133adce-3a75-4cb1-88e1-9ea4ae47fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of models to train with\n",
    "models = []\n",
    "models.append(('Linaer Discriminant Analysis',LinearDiscriminantAnalysis()))\n",
    "models.append(('Logistic Regression',LogisticRegression()))\n",
    "# models.append(('SVM',LinearSVC(max_iter=10000,dual=\"auto\")))\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('DecisionTree',DecisionTreeClassifier(random_state=0)))\n",
    "models.append(('RandomForest',RandomForestClassifier(random_state=0)))\n",
    "models.append(('GradientBoost',GradientBoostingClassifier(random_state=0)))\n",
    "models.append(('XGBoost',XGBClassifier(random_state=0,objective='binary:logistic')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3d03c-048d-412a-ae42-4ec85e0d65b6",
   "metadata": {},
   "source": [
    "### Fitting the Models to the Data Using the Default Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfeb136-a312-4310-8b64-5ad31b215886",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier, model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    Q = model.predict_proba(X_test)[:,1]\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test,y_test_pred)\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test,y_test_pred,sample_weight=None).ravel()\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "    roc_auc = auc(fpr,tpr)  \n",
    "    print(\"Classifier: {}\".format(classifier))    \n",
    "    print(\"Accuracy Score on Training Data = {:.4f}\".format(train_accuracy))    \n",
    "    print(\"Performance on Testing Data:\")\n",
    "    print(\"Accuracy Score = {:.4f}\".format(test_accuracy))    \n",
    "    print(\"True Positive Rate = {:.4f}\".format(TPR))\n",
    "    print(\"True Negative Rate = {:.4f}\".format(TNR))\n",
    "    print(\"F1 Score= {:.4f}\".format(f1))\n",
    "    print(\"Precision Score= {:.4f}\".format(precision))\n",
    "    print(\"AUC= {:.4f}\".format(roc_auc))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477db95-4a64-42dc-921b-86b0410b1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paramater Tuning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e8a75-f486-4b0c-8435-60d679670044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_tuning(model, model_param_grid):\n",
    "    clf = GridSearchCV(model, model_param_grid, cv=3, scoring=['f1', 'recall'], refit='f1')\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a0cd2-ecce-423f-9697-b45f9839ce61",
   "metadata": {},
   "source": [
    "### Optimal Threshold Determining Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135492d0-7571-4c5c-a249-2ac8b7c4666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_threshold(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    Q = model.predict_proba(X_test)[:,1]\n",
    "    THRESHOLD = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    results = pd.DataFrame(columns=[\"THRESHOLD\", \"accuracy\", \"true positive rate\", \"true negative rate\", \"F1 Score\", \"Precision Score\", \"AUC\"]) # df to store results\n",
    "    results['THRESHOLD'] = THRESHOLD\n",
    "    for i in range(9):                                                                         # iterate over each threshold\n",
    "      preds = np.where(Q>THRESHOLD[i], 1, 0)                                                 # if prob > threshold, predict 1\n",
    "      test_accuracy = accuracy_score(y_test,preds)\n",
    "      TN, FP, FN, TP = confusion_matrix(y_test,preds,sample_weight=None).ravel()\n",
    "      TPR = TP/(TP+FN)\n",
    "      TNR = TN/(TN+FP)\n",
    "      f1 = f1_score(y_test,preds)\n",
    "      fpr, tpr, _ = roc_curve(y_test, Q)\n",
    "      roc_auc = auc(fpr,tpr)  \n",
    "      precision = precision_score(y_test,preds)\n",
    "      results.iloc[i,1] = test_accuracy\n",
    "      results.iloc[i,2] = TPR\n",
    "      results.iloc[i,3] = TNR\n",
    "      results.iloc[i,4] = f1\n",
    "      results.iloc[i,5] = precision\n",
    "      results.iloc[i,6] = roc_auc\n",
    "    best_row = results.sort_values(['F1 Score', 'true positive rate'], ascending=[False, False]).iloc[0]\n",
    "    output = pd.DataFrame(best_row).T\n",
    "    output.columns = [\"Optimal Threshold\", \"Accuracy\", \"True Positive Rate\", \"True Negative Rate\", \"F1 Score\", \"Precision Score\", \"AUC\"]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1410ae6-8cd6-4bcc-9688-be5ab8eca629",
   "metadata": {},
   "source": [
    "### Logistic Regression - L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9c825-4692-4738-b862-1e5a668fe9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr2_param_grid = {'C': np.linspace(0.1,10,100)}\n",
    "lgr2 = LogisticRegression(penalty='l2') # L2 Penalty\n",
    "lgr2_reg_params = optimal_tuning(lgr2, lgr2_param_grid)['C']\n",
    "lgr2 = LogisticRegression(penalty='l2',C=lgr2_reg_params)\n",
    "threshold = optimal_threshold(lgr2)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064dff4-aef9-4302-a7bd-00e8e20bd3f8",
   "metadata": {},
   "source": [
    "### Logistic Regression - L1 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12548ee0-05c2-409f-a885-5399d9e39b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr1_param_grid = {'C': np.linspace(0.05,5,100)}\n",
    "lgr1 = LogisticRegression(solver='liblinear',penalty='l1') # L1 Penalty\n",
    "lgr1_reg_params = optimal_tuning(lgr1, lgr1_param_grid)['C']\n",
    "lgr1 = LogisticRegression(solver='liblinear',penalty='l1',C=lgr1_reg_params)\n",
    "threshold = optimal_threshold(lgr1)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482446f-3c28-457f-a940-0f7c907ac2bf",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003653e9-19c7-4ec5-aab0-74356aaa43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param_grid = {'solver': ['svd', 'lsqr', 'eigen'],\n",
    "                  'shrinkage': [None, 'auto', np.linspace(0,1,100)]}\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_params = optimal_tuning(lda, lda_param_grid)\n",
    "lda = LinearDiscriminantAnalysis(solver=lda_params['solver'], shrinkage=lda_params['shrinkage'])\n",
    "threshold = optimal_threshold(lda)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f55c63-6402-4b36-8d42-90659ce6c42b",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc4070-3654-487f-b168-2a35a86c575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    'max_depth': [np.linspace(2, 20, 10, dtype=int), None],\n",
    "    'min_samples_split': np.linspace(0.1, 1.0, 10),\n",
    "    'min_samples_leaf': np.linspace(0.1, 0.5, 5),\n",
    "    'max_features': [None, 'sqrt', 'log2', np.linspace(0.1, 1.0, 10)],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt_params = optimal_tuning(dt, dt_param_grid)\n",
    "dt = DecisionTreeClassifier(random_state=0,\n",
    "                            max_depth=dt_params['max_depth'],\n",
    "                            min_samples_split=dt_params['min_samples_split'],\n",
    "                            min_samples_leaf=dt_params['min_samples_leaf'],\n",
    "                            max_features=dt_params['max_features'],\n",
    "                            criterion=dt_params['criterion'])\n",
    "threshold = optimal_threshold(dt)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55ab91-0757-409f-9ef1-b3bf1d7b2654",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1988e1d-c388-44c1-baae-d25e3e9a9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': np.linspace(1, 20, 20, dtype=int),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': np.linspace(1, 10, 10, dtype=int)\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = optimal_tuning(knn, knn_param_grid)\n",
    "knn = KNeighborsClassifier(n_neighbors=knn_params['n_neighbors'],\n",
    "                           weights=knn_params['weights'],\n",
    "                           metric=knn_params['metric'],\n",
    "                           p=knn_params['p'])\n",
    "threshold = optimal_threshold(knn)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb62b3-7d89-4fc8-a911-d2f568a5d186",
   "metadata": {},
   "source": [
    "### Final Results of All Selected Classifiers in Sorted Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce097d3-87f7-4152-933c-1a08fb56a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.DataFrame(columns=[\"Optimal Threshold\", \"Accuracy\", \"True Positive Rate\", \"True Negative Rate\", \"F1 Score\", \"Precision Score\", \"AUC\"])\n",
    "final_results.loc['Logistic Regression - L2 Penalty'] = optimal_threshold(lgr2).iloc[0]\n",
    "final_results.loc['Logistic Regression - L1 Penalty'] = optimal_threshold(lgr1).iloc[0]\n",
    "final_results.loc['Linear Discriminant Analysis'] = optimal_threshold(lda).iloc[0]\n",
    "final_results.loc['Decision Tree'] = optimal_threshold(dt).iloc[0]\n",
    "final_results.loc['K-Nearest Neighbour'] = optimal_threshold(knn).iloc[0]\n",
    "final_results.sort_values(['F1 Score', 'True Positive Rate', \"Precision Score\", \"AUC\", \"True Negative Rate\", \"Accuracy\"], ascending=[False, False, False, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa196e80-5cb4-4249-aa78-d2d7112d1bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
